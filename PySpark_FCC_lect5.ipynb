{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# PYSPARK TUTORIAL - FCC"
      ],
      "metadata": {
        "id": "CzE-lT3rGTyz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "  ## **Lecture Numero Cinco**\n",
        "\n",
        "####**What will be covered:**\n",
        "\n",
        "- Groupby Functions\n",
        "- Aggregate Functions\n"
      ],
      "metadata": {
        "id": "ksApzIXlGWzp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z_Y0KZ4zGP_-",
        "outputId": "bd6b33cf-3e1a-4984-937d-03aa0bb152bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.5.0.tar.gz (316.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.9/316.9 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.5.0-py2.py3-none-any.whl size=317425344 sha256=dc59d134bae14895417e40fc56d449f9bb82fa942f880da8ae14d177433bb7b2\n",
            "  Stored in directory: /root/.cache/pip/wheels/41/4e/10/c2cf2467f71c678cfc8a6b9ac9241e5e44a01940da8fbb17fc\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.5.0\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pyspark\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark=SparkSession.builder.appName('Agg_Grp').getOrCreate()"
      ],
      "metadata": {
        "id": "01G_gMBUH00Z"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "mYu2r-EsIVCI",
        "outputId": "8be3070b-f486-4c04-8209-d7acdd2f85a5"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7d0a781dbb20>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://e4788f3eb7b0:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.5.0</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>Practise</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark=spark.read.csv('/content/drive/MyDrive/pyspark/nameage3.csv',header=True,inferSchema=True)\n",
        "df_pyspark.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SXfNrP65IVaC",
        "outputId": "feb8314a-3dc1-41c9-f8d4-02b9f351f708"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+------------+------+\n",
            "|     Name|  Department|Salary|\n",
            "+---------+------------+------+\n",
            "|    Krish|         IOT| 10000|\n",
            "|   Mahesh|    Big Data|  5000|\n",
            "|    Krish|    Big Data|  4000|\n",
            "|   Mahesh|Data Science|  4000|\n",
            "|Sudhanshu|Data Science|  3000|\n",
            "|Sudhanshu|         IOT| 20000|\n",
            "|Sudhanshu|    Big Data| 10000|\n",
            "|    Sunny|Data Science|  5000|\n",
            "|    Sunny|    Big Data| 10000|\n",
            "+---------+------------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Flt94kUpIgne",
        "outputId": "c876456c-3974-42f7-c9aa-0b2e21d42907"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Name: string (nullable = true)\n",
            " |-- Department: string (nullable = true)\n",
            " |-- Salary: integer (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Grouped to find the maximum salary\n",
        "# sum(): This part applies the sum aggregation function to each group. It calculates the sum of all numerical columns for each group.\n",
        "\n",
        "df_pyspark.groupBy('Name').sum().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hZpJ_iFrIiz8",
        "outputId": "dc61056d-c318-4138-9161-7ac5c8d7fe97"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+-----------+\n",
            "|     Name|sum(Salary)|\n",
            "+---------+-----------+\n",
            "|Sudhanshu|      33000|\n",
            "|    Krish|      14000|\n",
            "|   Mahesh|       9000|\n",
            "|    Sunny|      15000|\n",
            "+---------+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark.groupBy('Name').avg().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3GvDl65LI_UK",
        "outputId": "98144dad-619a-4586-ce65-c9bca92b96ef"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+-----------+\n",
            "|     Name|avg(Salary)|\n",
            "+---------+-----------+\n",
            "|Sudhanshu|    11000.0|\n",
            "|    Krish|     7000.0|\n",
            "|   Mahesh|     4500.0|\n",
            "|    Sunny|     7500.0|\n",
            "+---------+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark.groupBy('Department').sum().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K9ND2bSIJBL-",
        "outputId": "1403fdbd-2a06-4c61-80f9-11ac4821af4b"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+-----------+\n",
            "|  Department|sum(Salary)|\n",
            "+------------+-----------+\n",
            "|         IOT|      30000|\n",
            "|    Big Data|      29000|\n",
            "|Data Science|      12000|\n",
            "+------------+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark.groupBy('Department').mean().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xpaEa74uJDQd",
        "outputId": "74ca8e87-e33e-462b-ae94-3be38fa2b6c4"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+-----------+\n",
            "|  Department|avg(Salary)|\n",
            "+------------+-----------+\n",
            "|         IOT|    15000.0|\n",
            "|    Big Data|     7250.0|\n",
            "|Data Science|     4000.0|\n",
            "+------------+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark.groupBy('Department').count().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PPEtHdtSJEWi",
        "outputId": "f9c2555b-b1a6-41eb-f2fb-f4a376878503"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+-----+\n",
            "|  Department|count|\n",
            "+------------+-----+\n",
            "|         IOT|    2|\n",
            "|    Big Data|    4|\n",
            "|Data Science|    3|\n",
            "+------------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark.agg({'Salary':'sum'}).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HCJ-fF76JIi0",
        "outputId": "e57f51a6-5b6d-41da-e21b-6c7de422cc87"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+\n",
            "|sum(Salary)|\n",
            "+-----------+\n",
            "|      71000|\n",
            "+-----------+\n",
            "\n"
          ]
        }
      ]
    }
  ]
}