{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G38QhFB97Cjd"
      },
      "source": [
        "# PYSPARK TUTORIAL - FCC\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JBSf75ti7jJk"
      },
      "source": [
        "  ## **Lecture Numero Tres**\n",
        "\n",
        "####**What will be covered:**\n",
        "\n",
        "- Dropping Columns\n",
        "- Dropping Rows\n",
        "- Various Parameter In Dropping functionalities\n",
        "- Handling Missing values by Mean, Median And Mode\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3nvlmxFD77o2",
        "outputId": "45257642-486d-4d91-8edd-c9fda8a8f540"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.5.0.tar.gz (316.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.9/316.9 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.5.0-py2.py3-none-any.whl size=317425344 sha256=6bdc92b56d7928433ccfc06974e843e9fa548ff636c5eb32f7cd143ac0ee7f5b\n",
            "  Stored in directory: /root/.cache/pip/wheels/41/4e/10/c2cf2467f71c678cfc8a6b9ac9241e5e44a01940da8fbb17fc\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.5.0\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "cqkw5g236imV"
      },
      "outputs": [],
      "source": [
        "import pyspark\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark=SparkSession.builder.appName('Practise').getOrCreate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "4uZt-ue075BY",
        "outputId": "4508af2d-ed46-4757-ba07-a26ba355c061"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://776e003c7326:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.5.0</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>Practise</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ],
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x787611a00040>"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "spark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L4NzYKoi715A",
        "outputId": "ce50bffa-5be0-431c-df0e-4e18a5528107"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---------+----+----------+------+\n",
            "|     Name| Age|Experience|Salary|\n",
            "+---------+----+----------+------+\n",
            "|    Krish|  31|        10| 30000|\n",
            "|Sudhanshu|  30|         8| 25000|\n",
            "|    Sunny|  29|         4| 20000|\n",
            "|     Paul|  24|         3| 20000|\n",
            "|   Harsha|  21|         1| 15000|\n",
            "|  Shubham|  23|         2| 18000|\n",
            "|   Mahesh|NULL|      NULL| 40000|\n",
            "|     NULL|  34|        10| 38000|\n",
            "|     NULL|  36|      NULL|  NULL|\n",
            "+---------+----+----------+------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df_pyspark=spark.read.csv('/content/drive/MyDrive/pyspark/nameage1.csv',header=True,inferSchema=True)\n",
        "df_pyspark.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-24lSTE58SzY",
        "outputId": "3263e56d-8b26-4ff1-dba6-6f2acbd0b4f4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- Name: string (nullable = true)\n",
            " |-- Age: integer (nullable = true)\n",
            " |-- Experience: integer (nullable = true)\n",
            " |-- Salary: integer (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df_pyspark.printSchema()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tYzE-aPS8W9Q",
        "outputId": "9290aad8-9cd5-4aa5-b8b5-4825726a765d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+----+----------+------+\n",
            "| Age|Experience|Salary|\n",
            "+----+----------+------+\n",
            "|  31|        10| 30000|\n",
            "|  30|         8| 25000|\n",
            "|  29|         4| 20000|\n",
            "|  24|         3| 20000|\n",
            "|  21|         1| 15000|\n",
            "|  23|         2| 18000|\n",
            "|NULL|      NULL| 40000|\n",
            "|  34|        10| 38000|\n",
            "|  36|      NULL|  NULL|\n",
            "+----+----------+------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "##drop the column, but not permanently\n",
        "df_pyspark.drop('Name').show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mNxl_eoj88kW",
        "outputId": "613a1158-8ba4-48ba-be7b-9a37ad3be480"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---------+---+----------+------+\n",
            "|     Name|Age|Experience|Salary|\n",
            "+---------+---+----------+------+\n",
            "|    Krish| 31|        10| 30000|\n",
            "|Sudhanshu| 30|         8| 25000|\n",
            "|    Sunny| 29|         4| 20000|\n",
            "|     Paul| 24|         3| 20000|\n",
            "|   Harsha| 21|         1| 15000|\n",
            "|  Shubham| 23|         2| 18000|\n",
            "+---------+---+----------+------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# drop all rows with null\n",
        "df_pyspark.na.drop().show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dxT3TifF934b",
        "outputId": "9c3a19b1-0bef-4941-d2ec-25757a2d82d9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---------+---+----------+------+\n",
            "|     Name|Age|Experience|Salary|\n",
            "+---------+---+----------+------+\n",
            "|    Krish| 31|        10| 30000|\n",
            "|Sudhanshu| 30|         8| 25000|\n",
            "|    Sunny| 29|         4| 20000|\n",
            "|     Paul| 24|         3| 20000|\n",
            "|   Harsha| 21|         1| 15000|\n",
            "|  Shubham| 23|         2| 18000|\n",
            "+---------+---+----------+------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# anywhere null comes yeet that row\n",
        "df_pyspark.na.drop(how=\"any\").show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CnpMFGw4-UDL",
        "outputId": "d7abd1ed-5760-4d47-e4a4-ac8ba56cdb63"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---------+---+----------+------+\n",
            "|     Name|Age|Experience|Salary|\n",
            "+---------+---+----------+------+\n",
            "|    Krish| 31|        10| 30000|\n",
            "|Sudhanshu| 30|         8| 25000|\n",
            "|    Sunny| 29|         4| 20000|\n",
            "|     Paul| 24|         3| 20000|\n",
            "|   Harsha| 21|         1| 15000|\n",
            "|  Shubham| 23|         2| 18000|\n",
            "|     NULL| 34|        10| 38000|\n",
            "+---------+---+----------+------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# only drops rows with 3 nulls\n",
        "df_pyspark.na.drop(how=\"any\",thresh=3).show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zoa2YvLV--cX",
        "outputId": "69e8aa82-49c3-4e44-9f5b-5dc03503d1b7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---------+---+----------+------+\n",
            "|     Name|Age|Experience|Salary|\n",
            "+---------+---+----------+------+\n",
            "|    Krish| 31|        10| 30000|\n",
            "|Sudhanshu| 30|         8| 25000|\n",
            "|    Sunny| 29|         4| 20000|\n",
            "|     Paul| 24|         3| 20000|\n",
            "|   Harsha| 21|         1| 15000|\n",
            "|  Shubham| 23|         2| 18000|\n",
            "|     NULL| 34|        10| 38000|\n",
            "|     NULL| 36|      NULL|  NULL|\n",
            "+---------+---+----------+------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# drop the rows where age is null\n",
        "df_pyspark.na.drop(how=\"any\",subset=['Age']).show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZIpK2qO5_EgO",
        "outputId": "65b4c069-eab4-4ad8-83f8-6da925a360f5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------------+----+----------+------+\n",
            "|          Name| Age|Experience|Salary|\n",
            "+--------------+----+----------+------+\n",
            "|         Krish|  31|        10| 30000|\n",
            "|     Sudhanshu|  30|         8| 25000|\n",
            "|         Sunny|  29|         4| 20000|\n",
            "|          Paul|  24|         3| 20000|\n",
            "|        Harsha|  21|         1| 15000|\n",
            "|       Shubham|  23|         2| 18000|\n",
            "|        Mahesh|NULL|      NULL| 40000|\n",
            "|Missing Values|  34|        10| 38000|\n",
            "|Missing Values|  36|      NULL|  NULL|\n",
            "+--------------+----+----------+------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "### Filling the Missing Value\n",
        "df_pyspark.na.fill('Missing Values',['Name','age']).show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "phOwfEaAAOMr",
        "outputId": "ad768d91-8ded-42e1-82bc-8ae8c25b5fff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---------+----+----------+------+\n",
            "|     Name| Age|Experience|Salary|\n",
            "+---------+----+----------+------+\n",
            "|    Krish|  31|        10| 30000|\n",
            "|Sudhanshu|  30|         8| 25000|\n",
            "|    Sunny|  29|         4| 20000|\n",
            "|     Paul|  24|         3| 20000|\n",
            "|   Harsha|  21|         1| 15000|\n",
            "|  Shubham|  23|         2| 18000|\n",
            "|   Mahesh|NULL|      NULL| 40000|\n",
            "|     NULL|  34|        10| 38000|\n",
            "|     NULL|  36|      NULL|  NULL|\n",
            "+---------+----+----------+------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df_pyspark.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "bX6aq0QkAPn9"
      },
      "outputs": [],
      "source": [
        "from pyspark.ml.feature import Imputer\n",
        "\n",
        "imputer = Imputer(\n",
        "    inputCols=['Age', 'Experience', 'Salary'],\n",
        "    outputCols=[\"{}_imputed\".format(c) for c in ['Age', 'Experience', 'Salary']]\n",
        "    ).setStrategy(\"mean\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oP5NhTo2BgPb",
        "outputId": "0559656b-d5b3-4988-e16c-6e8f2b6c3f46"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---------+----+----------+------+-----------+------------------+--------------+\n",
            "|     Name| Age|Experience|Salary|Age_imputed|Experience_imputed|Salary_imputed|\n",
            "+---------+----+----------+------+-----------+------------------+--------------+\n",
            "|    Krish|  31|        10| 30000|         31|                10|         30000|\n",
            "|Sudhanshu|  30|         8| 25000|         30|                 8|         25000|\n",
            "|    Sunny|  29|         4| 20000|         29|                 4|         20000|\n",
            "|     Paul|  24|         3| 20000|         24|                 3|         20000|\n",
            "|   Harsha|  21|         1| 15000|         21|                 1|         15000|\n",
            "|  Shubham|  23|         2| 18000|         23|                 2|         18000|\n",
            "|   Mahesh|NULL|      NULL| 40000|         28|                 5|         40000|\n",
            "|     NULL|  34|        10| 38000|         34|                10|         38000|\n",
            "|     NULL|  36|      NULL|  NULL|         36|                 5|         25750|\n",
            "+---------+----+----------+------+-----------+------------------+--------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "imputer.fit(df_pyspark).transform(df_pyspark).show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "RhYTsqOHBhB0"
      },
      "outputs": [],
      "source": [
        "from pyspark.ml.feature import Imputer\n",
        "\n",
        "imputer = Imputer(\n",
        "    inputCols=['Age', 'Experience', 'Salary'],\n",
        "    outputCols=[\"{}_imputed\".format(c) for c in ['Age', 'Experience', 'Salary']]\n",
        "    ).setStrategy(\"median\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7KnRhKrcBovn",
        "outputId": "ebf6a4f5-af42-402f-bc89-c9e94dec6f68"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---------+----+----------+------+-----------+------------------+--------------+\n",
            "|     Name| Age|Experience|Salary|Age_imputed|Experience_imputed|Salary_imputed|\n",
            "+---------+----+----------+------+-----------+------------------+--------------+\n",
            "|    Krish|  31|        10| 30000|         31|                10|         30000|\n",
            "|Sudhanshu|  30|         8| 25000|         30|                 8|         25000|\n",
            "|    Sunny|  29|         4| 20000|         29|                 4|         20000|\n",
            "|     Paul|  24|         3| 20000|         24|                 3|         20000|\n",
            "|   Harsha|  21|         1| 15000|         21|                 1|         15000|\n",
            "|  Shubham|  23|         2| 18000|         23|                 2|         18000|\n",
            "|   Mahesh|NULL|      NULL| 40000|         29|                 4|         40000|\n",
            "|     NULL|  34|        10| 38000|         34|                10|         38000|\n",
            "|     NULL|  36|      NULL|  NULL|         36|                 4|         20000|\n",
            "+---------+----+----------+------+-----------+------------------+--------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "imputer.fit(df_pyspark).transform(df_pyspark).show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "mDwbXGBYCHZI"
      },
      "outputs": [],
      "source": [
        "from pyspark.ml.feature import Imputer\n",
        "\n",
        "imputer = Imputer(\n",
        "    inputCols=['Age', 'Experience', 'Salary'],\n",
        "    outputCols=[\"{}_imputed\".format(c) for c in ['Age', 'Experience', 'Salary']]\n",
        "    ).setStrategy(\"mode\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BUogy_MACKGN",
        "outputId": "4b749533-3d06-4941-d37a-24aa2413ef4b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---------+----+----------+------+-----------+------------------+--------------+\n",
            "|     Name| Age|Experience|Salary|Age_imputed|Experience_imputed|Salary_imputed|\n",
            "+---------+----+----------+------+-----------+------------------+--------------+\n",
            "|    Krish|  31|        10| 30000|         31|                10|         30000|\n",
            "|Sudhanshu|  30|         8| 25000|         30|                 8|         25000|\n",
            "|    Sunny|  29|         4| 20000|         29|                 4|         20000|\n",
            "|     Paul|  24|         3| 20000|         24|                 3|         20000|\n",
            "|   Harsha|  21|         1| 15000|         21|                 1|         15000|\n",
            "|  Shubham|  23|         2| 18000|         23|                 2|         18000|\n",
            "|   Mahesh|NULL|      NULL| 40000|         21|                10|         40000|\n",
            "|     NULL|  34|        10| 38000|         34|                10|         38000|\n",
            "|     NULL|  36|      NULL|  NULL|         36|                10|         20000|\n",
            "+---------+----+----------+------+-----------+------------------+--------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "imputer.fit(df_pyspark).transform(df_pyspark).show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
